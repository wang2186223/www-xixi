#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å°è¯´åº“ç®¡ç†å™¨ - æ”¯æŒå¢é‡æ›´æ–°å’Œå˜åŒ–æ£€æµ‹
é€‚é…æ–°çš„æ–‡ä»¶ç»“æ„ï¼šæ–‡ä»¶å¤¹å=å°è¯´æ ‡é¢˜ï¼Œæè¿°.txtï¼Œæ­£æ–‡.txt
"""

import os
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import chardet
import re


class SmartNovelLibraryManager:
    """æ™ºèƒ½å°è¯´åº“ç®¡ç†å™¨"""
    
    def __init__(self, source_path: str, output_path: str):
        self.source_path = Path(source_path)
        self.output_path = Path(output_path)
        self.index_file = self.output_path / "novels-index.json"
        self.cache_file = self.output_path / "novels-cache.json"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_path.mkdir(parents=True, exist_ok=True)
        
    def smart_scan_and_update(self) -> Dict:
        """æ™ºèƒ½æ‰«æå’Œæ›´æ–°å°è¯´åº“"""
        print("ğŸ” å¼€å§‹æ™ºèƒ½æ‰«æå°è¯´åº“...")
        
        # åŠ è½½å†å²ç¼“å­˜
        cache_data = self.load_cache()
        current_novels = {}
        changes = {
            'new': [],      # æ–°å¢çš„å°è¯´
            'updated': [],  # æ›´æ–°çš„å°è¯´
            'unchanged': [], # æœªå˜åŒ–çš„å°è¯´
            'removed': []   # åˆ é™¤çš„å°è¯´
        }
        
        # æ‰«æå½“å‰æ–‡ä»¶å¤¹
        if not self.source_path.exists():
            print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {self.source_path}")
            return {'novels': {}, 'changes': changes}
            
        print(f"ğŸ“‚ æ‰«æç›®å½•: {self.source_path}")
        
        for folder in self.source_path.iterdir():
            if not folder.is_dir():
                continue
                
            print(f"ğŸ“– æ£€æŸ¥å°è¯´: {folder.name}")
            
            # è§£æå°è¯´æ•°æ®
            novel_data = self.parse_novel_folder(folder)
            if not novel_data:
                continue
                
            novel_id = novel_data['slug']
            current_novels[novel_id] = novel_data
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
            if novel_id not in cache_data:
                # æ–°å¢å°è¯´
                changes['new'].append(novel_id)
                print(f"  âœ¨ æ–°å¢å°è¯´: {novel_data['title']}")
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
                cached_novel = cache_data[novel_id]
                if self.has_content_changed(novel_data, cached_novel):
                    changes['updated'].append(novel_id)
                    print(f"  ğŸ”„ å°è¯´æ›´æ–°: {novel_data['title']}")
                else:
                    changes['unchanged'].append(novel_id)
                    print(f"  âœ… æ— å˜åŒ–: {novel_data['title']}")
                    
        # æ£€æŸ¥åˆ é™¤çš„å°è¯´
        for novel_id in cache_data:
            if novel_id not in current_novels:
                changes['removed'].append(novel_id)
                print(f"  ğŸ—‘ï¸ å°è¯´åˆ é™¤: {cache_data[novel_id].get('title', novel_id)}")
                
        # ä¿å­˜ç¼“å­˜å’Œç´¢å¼•
        self.save_cache(current_novels)
        self.save_index(current_novels)
        
        print(f"\nğŸ“Š æ‰«æå®Œæˆ:")
        print(f"  æ–°å¢: {len(changes['new'])} æœ¬")
        print(f"  æ›´æ–°: {len(changes['updated'])} æœ¬")
        print(f"  æ— å˜åŒ–: {len(changes['unchanged'])} æœ¬")
        print(f"  åˆ é™¤: {len(changes['removed'])} æœ¬")
        
        return {
            'novels': current_novels,
            'changes': changes
        }
        
    def parse_novel_folder(self, folder_path: Path) -> Optional[Dict]:
        """è§£æå•ä¸ªå°è¯´æ–‡ä»¶å¤¹"""
        try:
            # æ–°çš„æ–‡ä»¶ç»“æ„ï¼šæè¿°.txt å’Œ æ­£æ–‡.txt
            desc_file = folder_path / "æè¿°.txt"
            content_file = folder_path / "æ­£æ–‡.txt"
            
            # å…¼å®¹æ—§æ ¼å¼
            if not desc_file.exists():
                desc_file = folder_path / "ä¹¦ç±æè¿°.txt"
            if not content_file.exists():
                content_file = folder_path / "ä¹¦ç±æ­£æ–‡.txt"
                
            if not desc_file.exists() or not content_file.exists():
                print(f"  âš ï¸ è·³è¿‡: ç¼ºå°‘å¿…éœ€æ–‡ä»¶ (éœ€è¦ æè¿°.txt å’Œ æ­£æ–‡.txt)")
                return None
                
            # è§£æå°è¯´ä¿¡æ¯
            novel_info = self.parse_description_file(desc_file)
            if not novel_info:
                print(f"  âŒ è§£ææè¿°æ–‡ä»¶å¤±è´¥")
                return None
                
            # è§£æç« èŠ‚å†…å®¹
            chapters = self.parse_content_file(content_file)
            if not chapters:
                print(f"  âŒ è§£ææ­£æ–‡æ–‡ä»¶å¤±è´¥")
                return None
                
            # æŸ¥æ‰¾å°é¢å›¾ç‰‡
            cover_file = self.find_cover_image(folder_path)
            
            # ç”Ÿæˆå°è¯´slugï¼ˆURLå‹å¥½çš„æ ‡è¯†ç¬¦ï¼‰
            title = novel_info.get('title', folder_path.name)
            slug = self.generate_slug(title)
            
            # è®¡ç®—æ–‡ä»¶æŒ‡çº¹ï¼ˆç”¨äºæ£€æµ‹å˜åŒ–ï¼‰
            content_hash = self.calculate_content_hash(desc_file, content_file)
            
            # æ„å»ºå°è¯´æ•°æ®
            novel_data = {
                'id': slug,
                'slug': slug,
                'title': title,
                'author': novel_info.get('author', 'Unknown Author'),
                'description': novel_info.get('description', ''),
                'short_description': self.generate_short_description(novel_info.get('description', '')),
                'genres': novel_info.get('genres', ['Romance', 'Werewolf']),
                'tags': novel_info.get('tags', ['alpha', 'mate', 'werewolf']),
                'status': novel_info.get('status', 'completed'),
                'rating': novel_info.get('rating', 4.5),
                'cover_path': str(cover_file) if cover_file else None,
                'chapters': chapters,
                'total_chapters': len(chapters),
                'word_count': sum(len(ch['content'].split()) for ch in chapters),
                'last_updated': datetime.now().strftime('%Y-%m-%d'),
                'created_at': datetime.now().strftime('%Y-%m-%d'),
                'folder_path': str(folder_path),
                'folder_name': folder_path.name,
                'content_hash': content_hash  # ç”¨äºæ£€æµ‹å˜åŒ–
            }
            
            return novel_data
            
        except Exception as e:
            print(f"  âŒ è§£æå¤±è´¥: {e}")
            return None
            
    def parse_description_file(self, file_path: Path) -> Optional[Dict]:
        """è§£ææè¿°æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        try:
            content = self.read_file_with_encoding(file_path)
            if not content:
                return None
                
            content = content.strip()
            info = {}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé”®å€¼å¯¹æ ¼å¼
            lines = content.split('\n')
            has_key_value_pairs = any(':' in line for line in lines[:5])  # æ£€æŸ¥å‰5è¡Œ
            
            if has_key_value_pairs:
                # é”®å€¼å¯¹æ ¼å¼
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                        
                    if ':' in line:
                        key, value = line.split(':', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        if key in ['ä¹¦ç±åç§°', 'æ ‡é¢˜', 'ä¹¦å', 'title']:
                            info['title'] = value
                        elif key in ['ä½œè€…', 'author']:
                            info['author'] = value
                        elif key in ['ç®€ä»‹', 'æè¿°', 'description']:
                            info['description'] = value
                        elif key in ['æ ‡ç­¾', 'tags']:
                            tags = [tag.strip() for tag in value.replace('ï¼Œ', ',').split(',') if tag.strip()]
                            info['tags'] = tags
                        elif key in ['çŠ¶æ€', 'status']:
                            status_map = {
                                'è¿è½½ä¸­': 'ongoing',
                                'å·²å®Œç»“': 'completed',
                                'å®Œç»“': 'completed',
                                'æš‚åœ': 'paused'
                            }
                            info['status'] = status_map.get(value, 'completed')
                        elif key in ['è¯„åˆ†', 'rating']:
                            try:
                                info['rating'] = float(value)
                            except:
                                info['rating'] = 4.5
            else:
                # çº¯æ–‡æœ¬æ ¼å¼ï¼ˆè‹±æ–‡æè¿°ï¼‰
                # ä»æ–‡ä»¶å¤¹åæå–æ ‡é¢˜
                folder_name = file_path.parent.name
                info['title'] = folder_name
                info['description'] = content
                
                # ä»æè¿°ä¸­æ¨æ–­æ ‡ç­¾å’Œç±»å‹
                description_lower = content.lower()
                tags = []
                genres = []
                
                # æ£€æµ‹ç‹¼äººç›¸å…³è¯æ±‡
                if any(word in description_lower for word in ['werewolf', 'wolf', 'alpha', 'pack', 'mate', 'luna']):
                    tags.extend(['werewolf', 'alpha', 'pack'])
                    genres.append('Werewolf')
                    
                # æ£€æµ‹é¾™ç›¸å…³è¯æ±‡
                if any(word in description_lower for word in ['dragon', 'drake', 'wyvern']):
                    tags.extend(['dragon', 'fantasy'])
                    genres.append('Fantasy')
                    
                # æ£€æµ‹æµ·æ´‹/æ·±æµ·ä¸»é¢˜
                if any(word in description_lower for word in ['ocean', 'sea', 'marine', 'underwater', 'abyss']):
                    tags.extend(['ocean', 'underwater', 'marine'])
                    genres.append('Fantasy')
                    
                # æ£€æµ‹çˆ±æƒ…å…ƒç´ 
                if any(word in description_lower for word in ['romance', 'love', 'forbidden', 'relationship']):
                    tags.append('romance')
                    genres.append('Romance')
                    
                # æ£€æµ‹CEOä¸»é¢˜
                if any(word in description_lower for word in ['ceo', 'billionaire', 'tycoon', 'executive']):
                    tags.extend(['ceo', 'billionaire', 'contemporary'])
                    genres.append('Contemporary')
                    
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç±»å‹ï¼Œé»˜è®¤ä¸ºæµªæ¼«å¹»æƒ³
                if not genres:
                    genres = ['Romance', 'Fantasy']
                if not tags:
                    tags = ['romance', 'fantasy']
                    
                info['tags'] = tags[:5]  # é™åˆ¶æ ‡ç­¾æ•°é‡
                info['genres'] = list(set(genres))[:3]  # å»é‡å¹¶é™åˆ¶ç±»å‹æ•°é‡
                
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            if 'title' not in info or not info['title']:
                # ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºæ ‡é¢˜
                info['title'] = file_path.parent.name
                
            # è®¾ç½®é»˜è®¤å€¼
            info.setdefault('author', 'Unknown Author')
            info.setdefault('description', '')
            info.setdefault('tags', ['romance', 'fantasy'])
            info.setdefault('genres', ['Romance', 'Fantasy'])
            info.setdefault('status', 'completed')
            info.setdefault('rating', 4.5)
            
            return info
            
        except Exception as e:
            print(f"  âŒ è§£ææè¿°æ–‡ä»¶é”™è¯¯: {e}")
            return None
            
    def parse_content_file(self, file_path: Path) -> List[Dict]:
        """è§£ææ­£æ–‡æ–‡ä»¶ï¼ŒæŒ‰ ### åˆ†å‰²ç« èŠ‚"""
        try:
            content = self.read_file_with_encoding(file_path)
            if not content:
                return []
                
            # æŒ‰ ### åˆ†å‰²ç« èŠ‚ï¼Œè¿™é‡Œå°±æ˜¯ç®€å•çš„ ### åˆ†å‰²
            chapter_parts = content.split('###')
            chapters = []
            
            for i, part in enumerate(chapter_parts):
                part = part.strip()
                if not part:
                    continue
                    
                # æå–ç« èŠ‚æ ‡é¢˜å’Œå†…å®¹
                lines = part.split('\n')
                first_line = lines[0].strip() if lines else ""
                
                # ç¡®å®šç« èŠ‚æ ‡é¢˜å’Œå†…å®¹èµ·å§‹ä½ç½®
                chapter_title = ""
                content_start_line = 0
                
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚ "chapter 1"ï¼‰
                if first_line and re.match(r'^chapter\s+\d+', first_line, re.IGNORECASE):
                    # æå–ç« èŠ‚å·
                    match = re.search(r'chapter\s+(\d+)', first_line, re.IGNORECASE)
                    if match:
                        chapter_num = match.group(1)
                        chapter_title = f"Chapter {chapter_num}"
                    else:
                        chapter_title = first_line.title()
                    content_start_line = 1
                else:
                    # å¦‚æœç¬¬ä¸€è¡Œä¸æ˜¯æ ‡å‡†çš„ç« èŠ‚æ ‡é¢˜ï¼Œä½¿ç”¨åºå·
                    chapter_title = f"Chapter {len(chapters) + 1}"
                    content_start_line = 0
                    
                # æå–ç« èŠ‚å†…å®¹ï¼ˆè·³è¿‡è£…é¥°æ€§åˆ†éš”ç¬¦ï¼‰
                content_lines = []
                for line in lines[content_start_line:]:
                    line_stripped = line.strip()
                    # è·³è¿‡çº¯è£…é¥°æ€§çš„è¡Œï¼ˆå¦‚ ********* æˆ– --------- ï¼‰
                    if not line_stripped or line_stripped == '*' * len(line_stripped) or line_stripped == '-' * len(line_stripped):
                        continue
                    content_lines.append(line)
                    
                chapter_content = '\n'.join(content_lines).strip()
                
                if chapter_content:  # åªæ·»åŠ æœ‰å†…å®¹çš„ç« èŠ‚
                    chapters.append({
                        'number': len(chapters) + 1,
                        'title': chapter_title,
                        'content': chapter_content,
                        'word_count': len(chapter_content.split()),
                        'publish_date': datetime.now().strftime('%Y-%m-%d')
                    })
                
            return chapters
            
        except Exception as e:
            print(f"  âŒ è§£ææ­£æ–‡æ–‡ä»¶é”™è¯¯: {e}")
            return []
            
    def find_cover_image(self, folder_path: Path) -> Optional[Path]:
        """æŸ¥æ‰¾å°é¢å›¾ç‰‡"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
        
        for file in folder_path.iterdir():
            if file.is_file() and file.suffix.lower() in image_extensions:
                return file
                
        return None
        
    def calculate_content_hash(self, desc_file: Path, content_file: Path) -> str:
        """è®¡ç®—å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹å˜åŒ–"""
        try:
            desc_content = self.read_file_with_encoding(desc_file) or ""
            content_content = self.read_file_with_encoding(content_file) or ""
            
            combined_content = desc_content + content_content
            return hashlib.md5(combined_content.encode('utf-8')).hexdigest()
        except:
            return ""
            
    def has_content_changed(self, new_novel: Dict, cached_novel: Dict) -> bool:
        """æ£€æŸ¥å°è¯´å†…å®¹æ˜¯å¦æœ‰å˜åŒ–"""
        # æ¯”è¾ƒå†…å®¹å“ˆå¸Œ
        new_hash = new_novel.get('content_hash', '')
        cached_hash = cached_novel.get('content_hash', '')
        
        if new_hash and cached_hash:
            return new_hash != cached_hash
            
        # å¦‚æœæ²¡æœ‰å“ˆå¸Œï¼Œæ¯”è¾ƒå…¶ä»–å­—æ®µ
        compare_fields = ['total_chapters', 'word_count', 'description']
        for field in compare_fields:
            if new_novel.get(field) != cached_novel.get(field):
                return True
                
        return False
        
    def read_file_with_encoding(self, file_path: Path) -> Optional[str]:
        """æ™ºèƒ½è¯»å–æ–‡ä»¶ï¼Œè‡ªåŠ¨æ£€æµ‹ç¼–ç """
        try:
            # é¦–å…ˆå°è¯•UTF-8
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            try:
                # æ£€æµ‹ç¼–ç 
                with open(file_path, 'rb') as f:
                    raw_data = f.read()
                    result = chardet.detect(raw_data)
                    encoding = result['encoding'] or 'utf-8'
                    
                # ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è¯»å–
                return raw_data.decode(encoding)
            except Exception as e:
                print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
                
    def generate_slug(self, title: str) -> str:
        """ç”ŸæˆURLå‹å¥½çš„slug"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
        slug = re.sub(r'[^\w\s-]', '', title.lower())
        slug = re.sub(r'[-\s]+', '-', slug)
        return slug.strip('-')
        
    def generate_short_description(self, description: str, max_length: int = 200) -> str:
        """ç”ŸæˆçŸ­æè¿°"""
        if len(description) <= max_length:
            return description
        return description[:max_length].rsplit(' ', 1)[0] + '...'
        
    def load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            if self.cache_file.exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        return {}
        
    def save_cache(self, novels: Dict) -> None:
        """ä¿å­˜ç¼“å­˜æ•°æ®ï¼ˆç« èŠ‚å†…å®¹é™åˆ¶ä¸ºå‰100ä¸ªå­—ç¬¦ï¼‰"""
        try:
            # åˆ›å»ºç¼“å­˜æ•°æ®ï¼Œé™åˆ¶ç« èŠ‚å†…å®¹é•¿åº¦
            cache_data = {}
            for novel_id, novel_data in novels.items():
                cache_data[novel_id] = novel_data.copy()
                
                # å¦‚æœæœ‰ç« èŠ‚æ•°æ®ï¼Œæˆªå–contentä¸ºå‰100ä¸ªå­—ç¬¦
                if 'chapters' in cache_data[novel_id]:
                    cache_data[novel_id]['chapters'] = []
                    for chapter in novel_data.get('chapters', []):
                        cached_chapter = chapter.copy()
                        # æˆªå–contentä¸ºå‰100ä¸ªå­—ç¬¦
                        if 'content' in cached_chapter and cached_chapter['content']:
                            cached_chapter['content'] = cached_chapter['content'][:100]
                        cache_data[novel_id]['chapters'].append(cached_chapter)
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜ç¼“å­˜æ–‡ä»¶ï¼ˆcontenté™åˆ¶100å­—ç¬¦ï¼‰: {self.cache_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
            
    def save_index(self, novels: Dict) -> None:
        """ä¿å­˜å°è¯´ç´¢å¼•ï¼ˆä»…å…ƒæ•°æ®ï¼‰"""
        try:
            # åˆ›å»ºåªåŒ…å«å…ƒæ•°æ®çš„ç´¢å¼•
            index_data = {}
            for novel_id, novel_data in novels.items():
                # åªä¿ç•™å…ƒæ•°æ®ï¼Œä¸åŒ…å«ç« èŠ‚å†…å®¹
                index_data[novel_id] = {
                    'id': novel_data.get('id'),
                    'slug': novel_data.get('slug'),
                    'title': novel_data.get('title'),
                    'author': novel_data.get('author'),
                    'description': novel_data.get('description'),
                    'short_description': novel_data.get('short_description'),
                    'genres': novel_data.get('genres', []),
                    'tags': novel_data.get('tags', []),
                    'status': novel_data.get('status'),
                    'rating': novel_data.get('rating'),
                    'cover_path': novel_data.get('cover_path'),
                    'total_chapters': novel_data.get('total_chapters', 0),
                    'last_updated': novel_data.get('last_updated'),
                    # ç« èŠ‚åˆ—è¡¨åªä¿ç•™å…ƒæ•°æ®ï¼Œä¸åŒ…å«content
                    'chapters': [
                        {
                            'number': ch.get('number'),
                            'title': ch.get('title'),
                            'word_count': ch.get('word_count', 0),
                            'publish_date': ch.get('publish_date')
                        }
                        for ch in novel_data.get('chapters', [])
                    ]
                }
            
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜ç´¢å¼•æ–‡ä»¶ï¼ˆä»…å…ƒæ•°æ®ï¼‰: {self.index_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
            
    def get_novels_for_homepage(self) -> List[Dict]:
        """è·å–é¦–é¡µå±•ç¤ºçš„å°è¯´åˆ—è¡¨"""
        try:
            if self.index_file.exists():
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    novels = json.load(f)
                    
                # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ›´æ–°æ—¶é—´æ’åº
                novel_list = list(novels.values())
                novel_list.sort(key=lambda x: x.get('last_updated', ''), reverse=True)
                
                return novel_list
        except Exception as e:
            print(f"âŒ è·å–å°è¯´åˆ—è¡¨å¤±è´¥: {e}")
            
        return []


# å…¼å®¹æ€§å‡½æ•°ï¼Œä¿æŒä¸æ—§ç‰ˆæœ¬çš„æ¥å£ä¸€è‡´
class NovelLibraryManager(SmartNovelLibraryManager):
    """å…¼å®¹æ€§ç±»ï¼Œä¿æŒæ—§æ¥å£"""
    
    def scan_and_update(self, force_rebuild: bool = False) -> Dict:
        """æ‰«æå’Œæ›´æ–°å°è¯´åº“"""
        if force_rebuild:
            # å¦‚æœå¼ºåˆ¶é‡å»ºï¼Œåˆ é™¤ç¼“å­˜
            if self.cache_file.exists():
                self.cache_file.unlink()
                
        result = self.smart_scan_and_update()
        
        # è¿”å›æ ¼å¼å…¼å®¹
        if 'changes' in result:
            return result
        else:
            return {
                'novels': result.get('novels', {}),
                'changes': {'new': [], 'updated': [], 'removed': []}
            }
